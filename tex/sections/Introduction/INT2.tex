\iffalse
Please check these links from the ref.bib yourself. Most of them are internet pages. (some only secondary sources, i.e. articles, so they may be useless). Some whitepapers\\
Health: \cite{HyperledgerHealth}\\
Insurance Services \cite{StateFarmSubrogation}   secondary sources: \cite{StateFarmQuorum, StateFarmQuorum2}\\
Financial: \cite{IBMSettlements, Libra}\\
Supply Chain:  \cite{IBMFoodSupply, DeloitteSupply}   secondary sources: \cite{SupplyExamples,}\\
Other:  \cite{HyperledgerTelecom}  secondary sources: \cite{AutoInventory}\\
\fi


This paper presents the design and evaluation of \sys{}, the first leaderless and scalable transactional key-value store that is robust to Byzantine faults.

Safe and efficient online data sharing among mutually distrustful
parties offers exciting opportunities for a variety of applications,
including healthcare~\cite{HyperledgerHealth}, financial services~\cite{IBMSettlements, Libra, StateFarmSubrogation}, supply chain
management~\cite{IBMFoodSupply, DeloitteSupply} and more~\cite{HyperledgerTelecom}. Consider the supply chain for the latest iPhone: it spans three continents, and hundreds of different contractors \cite{AppleSup} that may neither trust Apple, nor each other, yet must be willing to share and agree on information concerning the construction of the same product.
Byzantine fault tolerant (BFT)
systems~\cite{castro1999practical,martin2006fast,kotla2007zyzzyva,  gueta2018sbft,clement2009making,buchman2016tendermint,yin2019hotstuff,Clement09Upright,duan2014hbft, pires2018generalized,bessani2014state,lamport2011byzantizing,arun2019ezbft, malkhi2019flexible,duan2014hbft,yin2003separating, Guerraoui08Next, Kotla04High,liskov2010viewstamped} and permissioned blockchains~\cite{Hyperledger,EthereumQuorum, buchman2016tendermint, al2017chainspace,kokoris2018omniledger,gilad2017algorand, baudet2019state} are at the center of these new services. These protocols are guaranteed to
produce the same totally ordered log of operations across mutually distrustful
participants. 

The abstraction of a totally ordered log of operations is appealing simple. {\em Implementing} a totally ordered log, however, is hard to scale, as sequencing all requests can become a bottleneck \fs{sentence does not quite sound right: Implementations are hare to scale, "implementing" is not}. Fortunately, a total order is  often unnecessary, as most distributed applications primarily consist of independent and logically concurrent operations. Supply chains for instance, despite their name, are actually complex networks that generate and process logically concurrent transactions. 

Some BFT systems attempt to tap this opportunity for greater parallelism by leveraging sharding: operations within each shard continue to be totally ordered, but transactions that involve operations in disjoint (subsets of) shards can execute concurrently. Transactions involving  multiple shards are executed by running cross-shard atomic commit protocols that leverage the intra-shard total order of operations \cite{kokoris2018omniledger, al2017chainspace, zamani2018rapidchain, padilha2016callinicos}. 

These designs have several known drawbacks: \one~ they pay the performance penalty of  redundant coordination---both across shards (to commit distributed transactions) and among the replicas within each shard (to enforce total order)~\cite{zhang2016operation, zhang2015tapir, mu2016consolidating}; \two~within each shard,  they give to a leader disproportionate influence over the specific total order that is ultimately agreed upon: this has recently raised fairness concerns in the context of blockchains~\cite{herlihy2016enhancing, yin2019hotstuff}; and they restrict the expressiveness of the transactions they support~\cite{padilha2016callinicos}. \fs{the limited tx model is still kind of disjoint}

\changebars{}{Even more fundamentally, however, they are inherently limited in the concurrency  they can achieve, since, within each shard,  they continue to totally order logically concurrent operations. Sharding is simply too coarse a mechanism and its effectiveness too workload-dependent to fully expose parallelism.} \fs{do not like this sentence currently}
\nc{i think this paragraph is confusing and could be removed completely}

In this paper we advocate a more principled approach to support the abstraction of a totally ordered log \changebars{that expressingly exploits workloads' inherent parallelism}{while aggressively pursuing concurrency in its implementation}. In particular, we  make our own the lesson of distributed databases \fs{sounds a little odd to me, but I get the point}. These systems have long recognized that it is not necessary to implement a total order of transactions to offer the abstraction of a serializable execution: serializability, the gold-standard database criterion, defines a correct execution as one that is \textit{equivalent} to a serial schedule ~\cite{bernstein1979fas,Papadimitriou1979serializability,bernstein1979fas}.  This definition allows concurrent operations to execute in parallel and orders conflicting operations only.  We submit that Byzantine systems need be no different. This paper consequently argues for a paradigm "flip": rather that building a BFT data-sharing systems by layering database-like transactions and sharding on top of a BFT log, we  build out the abstraction of a BFT log atop a partially ordered distributed database.



\iffalse

% Existing research attempts to mitigate the aforementioned scalability bottleneck through a combination of sharding \changebars{and cross-shard atomic commit protocols, which they layer atop the totally ordered requests}{, cross-shard atomic commit protocols and centralised ordering services}~\cite{kokoris2018omniledger,al2017chainspace,padilha2016callinicos}. These systems suffer from three primary drawbacks \one ~ they limit the expressivity of the transactions they support \two ~ they introduce unnecessary coordination across replicas and finally, \three ~ they often centralise the ordering of requests at a single leader, which raises fairness \fs{and scalability - cyclic mention.. - instead single point of failure?} concerns. These limitations all stem from the same fallacy: the mistaken belief that building out a total order of operations is necessary for correctness.  \fs{these limitations currently don't read as if they are intertwined - when I think they should. I.e. the transaction expressiveness is limited in order to make the other limitations more scalable} \fs{transaction limited expressiveness only partially attributtable to total order imo - ; ALSO: the 2 blockchain citations use the UTXO model, its probably a stretch to say that has to due with totally ordered based? Even with partial order one-shot models are desirable (UTXO is a oneshot in my eyes), since thats single round communication/coordination}


\fs{people have been building the abstraction of a total order on top of a physical total order, i.e. the implementation mirrors abstraction. They KNOW that total order is limiting, its not a new idea or mistaken belief. The question is, whether it is possible to do it differently - we want to instead provide a different implementation. And people HAVE tried: But only for crash failure - or, only via sharding }

\fs{alternative version in comments}
\fi
\iffalse
Maintaining a totally ordered log of requests, despite its appealing simplicity, is problematic:
Such an approach is hard to scale \changebars{and costly to implement} as all agreement instances must be serialized, which in turn is often enforced by a dedicated sequencer, thus exposing both a throughput bottleneck and a single point of failure \fs{citation? Epaxos, BFT Mir: says leader is network bottleneck}. This total order is in fact often unnecessary; modern distributed applications primarily consist of independent operations that could be executed concurrently. Supply chains for instance, despite their name, are actually complex networks that generate and process logically concurrent transactions. \fs{2nd mention of supply chains as example already}
While this observation is frequently leveraged by distributed transaction protocols in the crash-fault model \cite{a bunch}, it has found scarce \cite{Clairvoyant} attention in the BFT space \fs{could we add a sentence for why? i.e. the simplicity of total order is so tempting?}.

Instead, existing research attempts to mitigate the aforementioned scalability bottleneck through the application of sharding and cross-shard atomic commit protocols on top of centralised ordering services~\cite{kokoris2018omniledger,al2017chainspace,padilha2016callinicos}. The application of sharding however, conflates the functionality of horizontal scalability with the objective of a partial-order and remains an engineering optimization dependent on workload-specific partition mappings.
On a high level, existing systems suffer from three primary drawbacks \one ~ they limit the expressivity of the transactions they support \fs{the above citations refer to UTXO models, bad comparison; I figure this is supposed to refer to things like Callinicos} \two ~ they introduce unnecessary coordination across replicas and finally,
\three ~ they often centralise the ordering of requests at a single leader, which, in addition to bottleneck concerns, raises fairness concerns for BFT settings. These limitations all stem from the same fallacy: the mistaken belief that building out a total order of operations is necessary for correctness. 
\fi



\iffalse 
In reality, building \textit{the abstraction} of a total order is sufficient, and distributed databases have long recognised this fact~\cite{crooks2018obladi,bernstein1979fas,Papadimitriou1979serializability,adya99weakconsis}. \fs{at this point a reader could expect us to talk about partial order and sharding - if we cut the Background section we currently do not mention sharding anywhere. That could seem ignorant.} Serializability, the gold-standard database criterion, defines a correct execution as one that is \textit{equivalent} to a correct schedule~\cite{bernstein1979fas,Papadimitriou1979serializability,bernstein1979fas}. This definition allows concurrent operations to execute in parallel and orders conflicting operations only.  Byzantine systems need be no different. This paper consequently argues for a paradigm "flip". The
right way to build BFT data-sharing systems is not to layer database-like transactions and sharding on top of a BFT log, but instead to do the opposite and build out the abstraction of a BFT log atop a partially ordered distributed database.
\fi
To this effect, we design \sys{}, the first leaderless and scalable key-value store that is resilient against
Byzantine faults, and specifically formalize the notion of \textit{Byzantine isolation}, the correctness
guarantee that any BFT distributed database should enforce.  \sys{} provides three main benefits.

 First, it overcomes the scalability bottleneck of a low-level
implementation based on a totally ordered BFT log. \sys instead leverages databases' ability to support highly concurrent transaction
processing while maintaining the abstraction
of a serial execution.

% an explicit ordering service 

Second, by doing away with an underlying totally ordered log, \sys{} can
sidestep the growing concerns~\cite{} about whether blockchains
order transactions fairly. Though the notion of fairness in this
context has not been rigorously defined, leaving the ordering to the
whim of a potentially Byzantine leader, as some protocols do~\cite{
Kotla07Zyzzyva,castro1999practical}
is intuitively problematic \cite{herlihy2016enhancing}. In contrast, \sys leaves the
responsibility of driving the replication and distributed commit of a
transaction to the client that proposes it \changebars{fs: cut imo}{and allows separate 
shards to order transactions independently as the total order abstraction afforded by Byzantine serializability can be maintained. } \fs{Limitation of client computation can come here: "A cost in doing so is higher computational load for clients"}

Third, \sys{} avoids the duplicate ordering costs of transactional systems
built on top of state machine replication. As Tapir noted~\cite{zhang2015tapir,mu2016consolidating},
these systems require a consistent ordering of
operations within each shard for replication, and additionally enforce a serial order of transactions across
shards for distributed commit. In contrast, \sys{} integrates distributed commit with 
replication and
limits coordination to the validation step of the distributed commit
protocol. %\fs{mention the shortcoming of using sharding for PO here}

In practice, reaping these benefits requires us to address several
technical obstacles. As in \fs{at this point we have not mentioned that we are OCC based} any OCC-based protocol, \sys
is vulnerable to aborts if transactions interleave unfavorably during
validation---but these concerns are compounded in a Byzantine
setting. First, since reading from a single local replica can no
longer guarantee integrity, it becomes necessary to read remotely,
thus increasing the window of time during which unfavorable interleavings may occur. Second, Byzantine clients and replicas may
collude to actively sabotage the commit chances of transactions issued
by correct clients. 

Byzantine behaviour in effect introduces a tension that is not present in non-Byzantine
distributed databases: optimistic and aggressive concurrency control mechanisms known
to improve performance (~\cite{kung1981occ,bernstein1983mcc,reed1983atomic,xie2015callas,zhang2015tapir}) in failure-free executions also increase the system's vulnerability to Byzantine faults. Consider for instance runtime pipelining~\cite{xie2015callas,su2017tebaldi} or multiversioned timestamp ordering (MVTSO)~\cite{bernstein1983mcc,reed1983atomic}: both allow writes to become visible to other operations before a transaction commits. While early write visibility helps reduce abort rates for
contended workload, it can cause transactions to stall on uncommitted operations whose writes they have observed. To mitigate this tension, we design \sys{} to follow the ethos of \textit{independent operability}: both safety (serializability) and liveness (the ability to issue and complete transactions) are \textit{local} properties. They remain, at all times, per client and per-object.  \fs{should be per-transation rather than per-object?}

%that system users experience \textit{independently/individually/seperately?}. \fs{check comments to see whether this improves vs old version.} \nc{I'm not entirely sure what it means by independently sorry}
%OLD: are \textit{local} properties

\mb{I am confused by the use of ``local.'' Are we using it the same
as Herlihy and Wing from the Linearizability paper? If not, I'd suggest we come
up with a different term to avoid confusion. For example, Serializabiliy is not
a local property of a system comprised of multiple objects (it is not the case
that the system is Serializable if and only if each object is Serializable).}
\fs{ What we mean is that a client "chooses" to experience serializability, so it is experienced locally per-client. Also, technically its not per-object, but rather per-object-group that a transaction touches. The same goes for liveness: clients experience it individually, and liveness  is on transaction grouping, not per-object.}



Specifically, we develop a variant of multiversion timestamp ordering that limits Byzantine clients ability to unilaterally abort honest clients' transactions%\fs{This is currently too strong. Can we be more clear about how our MVTSO achieves this? The things that come to mid are that writes are delayed and do not have external effect early, we dont accept writes that have high TS, and dependencies are only on f+1 matching reads}
 We additionally develop a novel \textit{fallback} mechanism that allows clients to finish others' pending transactions when stalled, without empowering Byzantine participants to skew results \fs{want to imply that Byz independence is not vulnerable to this: another client could only decide which Quorums are used, not make it fully abort/commit arbitrarily}. Importantly, this fallback mechanism is per-transaction, and can thus take place concurrently with other non-conflicting operations. This is in contrast with traditional BFT view-changes which fully preclude normal operation processing. Finally, we remain, at all times, fully leaderless. \fs{not true for the fallback, where we intentionally elect a leader, albeit this leader has very minimal influence - i.e. it cannot propose requests or unilaterally decide results - it is simply a dedicated coordinator. Furthermore - each TX HAS a leader, the client itself - The difference is, that in Indicus each Tx has its own leader (which is usually the client, but can become a replica). We do not want to mislead.}

Naturally, \sys{} also has limitations. First, it shifts some
responsibilities from replicas to clients, which increases a client's computation load. Second, \sys{} is optimistic: it greedily allows transactions to read uncommitted data and allows replicas to process operations out of order. This approach can lead to high abort rates under heavy contention.
\nc{while i think we should include
limitations because that's a good thing to do, it's not obvious to me that the above paragraph is useful. Those limitations seem kinda obvious?}
\fs{agree, the interleaving vulnerability part is also mentioned already. The client cost can be moved up - see earlier comment}

In summary, we make the following three contributions: 
\begin{itemize}
\item We introduce the notion of Byzantine Isolation and prove that \sys guarantees
Byzantine Serializability.
\item We introduce a novel concurrency control and recovery \fs{is "recovery" the right word? Its to support liveness - but yes, technically thats recovery from Byz failure} mechanism that balance the need for high-throughput in
the common case with resilience to Byzantine attacks.
\item Our system remains leaderless and exhibits linear communication complexity, unlike prior BFT systems. \fs{this describes Q/U too, so its not quite "unlike prior" - but we offer transactions and liveness}
\end{itemize}


The rest of the paper is structured as follows. Section~\ref{section:model} formalises \sys{}'s correctness guarantees.
Section~\ref{section:arch} outlines
\sys's architecture; we summarise our concurrency control control protocols and recovery protocols in \S\ref{section:exec} and \S\ref{section:rec}. We
prove correctness in \S\ref{sec::fallback} and evaluate \sys in \S\ref{section:eval}. Finally, we summarise related work (\S\ref{section:rel}) and conclude (\S\ref{section:conc}).

