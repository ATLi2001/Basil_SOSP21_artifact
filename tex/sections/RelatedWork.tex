
%-------------------------------------------------------------------------------
\section{Related Work/Comparison}  
%-------------------------------------------------------------------------------
A lot of recent effort has gone into designing high throughput and low latency databases that leverage synergies between transaction and replication layer to squeeze out any last performance. The recently proposed TAPIR transaction protocol leverages redundancy between transaction ordering and replication ordering to reduce total roundtrips, thus reducing latency in wide area networks. TAPIR shares several similarities with our system, most notably the absence of a leader and the resulting unordered validation structure. TAPIR too, leverages optimistic concurrency control to allow for concurrency among commutative transactions. When congestion is high however, throughput and tail latency worsen as abort rate grows. Janus avoids transaction aborts by dynamically re-ordering conflicting transactions \cite{mu2016consolidating}. This however, is made possible by assuming one-shot transactions, i.e. fixed read/write keys, and thus reduces the application generality. Another key-value store, Carousel, similarly assumes a restricted Transaction model in order to parallelize execution and validation \cite{yan2018carousel}. CURP too, leverages commutativity in order to reduces replication costs by making requests durable first, and only ordering them later \cite{park2019exploiting}. 

While all of these databases offer low latency replication, they are fundamentally limited to tolerating crash-failures. This strong failure assumption makes them less secure and not suitable for storing mission-critical, financial or highly sensitive data. The problem of tolerating arbitrary failures was originally formalized as \textit{Byzantine Generals Problem} \cite{lamport2019byzantine}, paving the way for countless Byzantine Fault Tolerant (BFT) protocols and implementations \cite{castro1999practical, martin2006fast, kotla2007zyzzyva, pires2018generalized, bessani2014state, lamport2011byzantizing, arun2019ezbft, malkhi2019flexible, duan2014hbft, yin2003separating}. Such protocols have a reputation of being are both notoriously difficult to understand and design correctly \cite{abraham2017revisiting, abraham2018revisiting, shrestha2019revisiting}, and in practice often impose significant overhead compared to its crash-failure tolerant counterparts, hence limiting frequent industrial adoption.
Recently however, with the surge in Blockchain interest, BFT protocols are experiencing a second Spring. While originally developed to tolerate arbitrary bugs, these protocols find increasing importance in settings where participants are untrusted or malicious. Permissioned Blockchains, organized by a consortium of registered participants can use traditional BFT State Machine Replication (SMR) protocols in order to achieve agreement. 
\fs{mention basic BFT first? pBFT is the first "practical", not the first BFT}
The seminal practical BFT (PBFT) protocol \cite{castro1999practical} implements a primary backup scheme that achieves consensus in three broadcast rounds, maintaining safety as long as the number of faulty participants is $<1/3$ (i.e. $n\geq 3f+1$), and offering liveness during synchronous operation. When primaries misbehave, a dedicated \textit{view-change protocol} allows for safe reconciliation. There have been numerous adaptations that aim to speed up common case and failure free execution such as FaB \cite{martin2006fast}, and most notably Zyzzyva \cite{kotla2007zyzzyva} which leverages speculative execution and a semi-client driven protocol to reduce latency. Akin to Indicus, replicas in Zyzzyva speculatively execute requests out-of-order, and rely on honest clients for reconciliation. Zyzzyva replicas however, \textit{expect} to process requests in-order, and diverge only temporarily as result of a byzantine leader. hBFT builds on Zyzzyva and attempts to improve faulty case behavior by returning the client responsibility of detecting inconsistencies to a dedicated replica checkpointing protocol. 
UpRight explores efforts to tolerate both byzantine and crash failures in order to make the overhead of deplyoing a BFT system practical
SBFT \cite{gueta2018sbft} pursues the goal of scaling to scale to large replication degrees, while offering light clients and high throughput under benign faults. It adopts the UpRight replication model, and modifies PBFT by utilizing collectors, threshold signatures and a fast path akin to Zyzzyva. 
Aardvark \cite{clement2009making} emphasizes the importance of robust performance under byzantine failures by adding increased client and replica checks and imposing frequent leader rotation by steadily increasing throughput requirements. Tendermint \cite{buchman2016tendermint} pushes this idea to the extreme by rotating leaders continuously, at the cost of assuming a synchronous network. Herlihy and Mor attempt to rigorize fairness properties for permissioned Blockchains and propose techniques to increase accountability for Tendermint specifically \cite{herlihy2016enhancing}.

HotStuff too, explores the use of rotating leaders by exploiting the symmetry in PBFTs phases in order to pipeline transaction processing \cite{yin2019hotstuff}. 
Nevertheless, all protocols derived from the PBFT family suffer from the leader bottleneck as well as enforcing a total order even on commutative operations. BFT-Mir \cite{stathakopoulou2019mir} identifies the proposal speed of a single leader as the practical bottleneck in most implementations and improves upon this by allowing all replicas to act as proposers.
Biblos \cite{bazzi2018clairvoyant} achieves leaderless SMR by leveraging a non-skipping timestamp protocol. It furthermore allows for commutative transactions to be executed in parallel at the cost of requiring read/write key sets to be known in advance. In order to preserve liveness however, Bilbos falls back to a PBFT resolution. \fs{Uses all to all, predefined TX, pbft fallback, timestamp phase and proofs required}
The Quorum/Update (Q/U) protocol too, offers leaderless agreement by leveraging Qurorums for a agreement in a limited read/write interface, but fails to terminate under contention \cite{abd2005fault}. To reconcile this shortocming, the Hybrid Quorum protocol (HQ) explores a hybrid solution, extending upon Q/U by adding a PBFT fallback path under contention \cite{cowling2006hq}. Liskov et Al further explore byzantine Quorum protocols for a Read/Write interface, giving special attention to bounding the effects of byzantine clients \cite{liskov2006tolerating}. 
\fs{BFT protocols under fire: \cite{singh2008bft} that one-size-fits-all protocols may be hard if not impossible to design in practice}
All of the above systems, including Indicus, guarantee Liveness only under the assumption of some degree of synchrony. This is consistent with the well known FLP impossibility result stating that no deterministic consensus solution may exist in the presence of asynchrony \cite{fischer1985impossibility}. Protocols such as Ben-Or's algorithm \cite{ben1983another}, HoneybadgerBFT \cite{miller2016honey} or BEAT \cite{duan2018beat} sidestep this result by introducing randomization, thus enabling probabilistic agreement even during asynchrony.

While the literature on BFT state machine replication is extensive, the efforts to offer a transactional interface for BFT are scarce. SMR itself can be utilized as a straw-man system to implement pre-defined Transactions (one-shot or stored procedures) by enforcing a common total order  in which replicas will execute the transactions. 
HRDB offers a dedicated BFT Database, but assumes a trusted shepheard layer, thus not being truly BF resilient \cite{vandiver2007tolerating}.
Byantium offers Snapshot Isolation for Transactions by re-purposing PBFT as atomic broadcast. It executes requests only at a primary and uses replicas to validate results in the total order defined by the SMR protocol \cite{garcia2011efficient}. Augustus implements short-transactions, a limited, comparison/query/update transaction model that declares all operations before execution \cite{padilha2013augustus}. It offers scalability via partitioning and achieves consistency within partitions by utilizing atomic broadcast. While Augustus assumes an optimistic execution model that allows for aborts under concurrency, its follow up work Callinicos implements a locking scheme in order to avoid Transaction aborts \cite{padilha2016callinicos}. To do so efficiently it resorts to a limited transaction model that requires knowledge of read/write sets and otherwise locks an entire partition in order to guarantee mutual exclusion, thus voiding any concurrency. BFT Deferred Update Replication adopts an interactive OCC transaction model comparable to ours, allowing execution to be speculative at clients \cite{pedone2012byzantine}. However, it uses PBFT atomic broadcast to enforce SMR on validation, thus resorting to both a leader, and a total order on all requests. It moreover does not extend to multiple shards.
In the Blockchain world, Chainspace \cite{al2017chainspace} and Omniledger \cite{kokoris2018omniledger} implement sharding by layering 2PC and atomic broadcast (within shards) for the UTXO transaction model. Rapidchain \cite{zamani2018rapidchain} offers efficient sharding for a permissionless system (what else? didnt read much, not so relevant). Hyperledger provides an enterprise-ready permissioned blockchain solution that simulates optimistic transaction processing by letting replicas speculatively execute Smart Contracts. While Hyperledger \cite{Hyperledger} describes itself as a shared database, it relies on a dedicated SMR ordering service that enforces a total order, and, in practice, only tolerates crash failures (Hyperledger uses Raft \cite{ongaro2014search}, a consensus protocol for the Crash-Failure model,  but can be extended to use PBFT). Sharma et al. attempt to \textit{databaseify} Hyperledger by adding database techniques such as transaction re-ordering in order to reduce aborts, but fundamentally maintains the totally ordered (Hyper-) ledger design. \fs{Databasify paper: tries to add some bandaid db techniques to hyperledger. Transaction re-ordering (still total order), and early aborts.} 
 \fs{(Mention other Permissioned Blockchain systems: Ethereum Quorum? (uses Raft or IstanbulBFT = implementation of pbft)}

DAG-based architectures \cite{pervez2018comparative}(IoT-chain, IOTA, Byteball - all are blockless) have been explored in the permissionless blockchain setting in order to parallelize consensus instances. While these increase throughput, they target permissionelss settings with Proof of Work/Stake, rather than permissioned BFT-based solutions, and it is unclear how to merge these approaches. \fs{finality speed does not improve.} Latency is no where near permissioned BFT systems.






\fs{How does all this related work compare to Indicus?}

